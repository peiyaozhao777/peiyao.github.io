
@article{alom2018history,
  title = {The {{History Began}} from {{AlexNet}}: {{A Comprehensive Survey}} on {{Deep Learning Approaches}}},
  shorttitle = {The {{History Began}} from {{AlexNet}}},
  author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
  year = {2018},
  month = sep,
  abstract = {Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].},
  archiveprefix = {arXiv},
  eprint = {1803.01164},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/8AKHPEK4/Alom et al. - 2018 - The History Began from AlexNet A Comprehensive Su.pdf;/home/jbo/Zotero/storage/FY82SR2J/1803.html},
  journal = {arXiv:1803.01164 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{bauerle2021net2vis,
  title = {{{Net2Vis}} -- {{A Visual Grammar}} for {{Automatically Generating Publication}}-{{Tailored CNN Architecture Visualizations}}},
  author = {B{\"a}uerle, Alex and {van Onzenoodt}, Christian and Ropinski, Timo},
  year = {2021},
  pages = {1--1},
  issn = {1077-2626, 1941-0506, 2160-9306},
  doi = {10.1109/TVCG.2021.3057483},
  abstract = {To convey neural network architectures in publications, appropriate visualizations are of great importance. While most current deep learning papers contain such visualizations, these are usually handcrafted just before publication, which results in a lack of a common visual grammar, significant time investment, errors, and ambiguities. Current automatic network visualization tools focus on debugging the network itself and are not ideal for generating publication visualizations. Therefore, we present an approach to automate this process by translating network architectures specified in Keras into visualizations that can directly be embedded into any publication. To do so, we propose a visual grammar for convolutional neural networks (CNNs), which has been derived from an analysis of such figures extracted from all ICCV and CVPR papers published between 2013 and 2019. The proposed grammar incorporates visual encoding, network layout, layer aggregation, and legend generation. We have further realized our approach in an online system available to the community, which we have evaluated through expert feedback, and a quantitative study. It not only reduces the time needed to generate network visualizations for publications, but also enables a unified and unambiguous visualization design.},
  archiveprefix = {arXiv},
  eprint = {1902.04394},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/YY2EPVWV/Bäuerle et al. - 2021 - Net2Vis -- A Visual Grammar for Automatically Gene.pdf;/home/jbo/Zotero/storage/M9GZ968J/1902.html},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{branson2018google,
  title = {From {{Google Maps}} to a {{Fine}}-{{Grained Catalog}} of {{Street}} Trees},
  author = {Branson, Steve and Wegner, Jan Dirk and Hall, David and Lang, Nico and Schindler, Konrad and Perona, Pietro},
  year = {2018},
  month = jan,
  volume = {135},
  pages = {13--30},
  issn = {09242716},
  doi = {10.1016/j.isprsjprs.2017.11.008},
  abstract = {Up-to-date catalogs of the urban tree population are of importance for municipalities to monitor and improve quality of life in cities. Despite much research on automation of tree mapping, mainly relying on on dedicated airborne LiDAR or hyperspectral campaigns, tree detection and species recognition is still mostly done manually in practice. We present a fully automated tree detection and species recognition pipeline that can process thousands of trees within a few hours using publicly available aerial and street view images of Google MapsTM. These data provide rich information from different viewpoints and at different scales from global tree shapes to bark textures. Our work-flow is built around a supervised classification that automatically learns the most discriminative features from thousands of trees and corresponding, publicly available tree inventory data. In addition, we introduce a change tracker that recognizes changes of individual trees at city-scale, which is essential to keep an urban tree inventory up-to-date. The system takes street-level images of the same tree location at two different times and classifies the type of change (e.g., tree has been removed). Drawing on recent advances in computer vision and machine learning, we apply convolutional neural networks (CNN) for all classification tasks. We propose the following pipeline: download all available panoramas and overhead images of an area of interest, detect trees per image and combine multi-view detections in a probabilistic framework, adding prior knowledge; recognize fine-grained species of detected trees. In a later, separate module, track trees over time, detect significant changes and classify the type of change. We believe this is the first work to exploit publicly available image data for city-scale street tree detection, species recognition and change tracking, exhaustively over several square kilometers, respectively many thousands of trees. Experiments in the city of Pasadena, California, USA show that we can detect {$>$} 70\% of the street trees, assign correct species to {$>$} 80\% for 40 different species, and correctly detect and classify changes in {$>$} 90\% of the cases.},
  archiveprefix = {arXiv},
  eprint = {1910.02675},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/55QJA734/Branson et al. - 2018 - From Google Maps to a Fine-Grained Catalog of Stre.pdf},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en}
}

@article{carpentier2018tree,
  title = {Tree {{Species Identification}} from {{Bark Images Using Convolutional Neural Networks}}},
  author = {Carpentier, Mathieu and Gigu{\`e}re, Philippe and Gaudreault, Jonathan},
  year = {2018},
  month = jul,
  abstract = {Tree species identification using bark images is a challenging problem that could prove useful for many forestry related tasks. However, while the recent progress in deep learning showed impressive results on standard vision problems, a lack of datasets prevented its use on tree bark species classification. In this work, we present, and make publicly available, a novel dataset called BarkNet 1.0 containing more than 23,000 high-resolution bark images from 23 different tree species over a wide range of tree diameters. With it, we demonstrate the feasibility of species recognition through bark images, using deep learning. More specifically, we obtain an accuracy of 93.88\% on single crop, and an accuracy of 97.81\% using a majority voting approach on all of the images of a tree. We also empirically demonstrate that, for a fixed number of images, it is better to maximize the number of tree individuals in the training database, thus directing future data collection efforts.},
  archiveprefix = {arXiv},
  eprint = {1803.00949},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/IYC3SGJR/Carpentier et al. - 2018 - Tree Species Identification from Bark Images Using.pdf;/home/jbo/Zotero/storage/EZUR3XQH/1803.html},
  journal = {arXiv:1803.00949 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{csillik2018identification,
  title = {Identification of {{Citrus Trees}} from {{Unmanned Aerial Vehicle Imagery Using Convolutional Neural Networks}}},
  author = {Csillik, Ovidiu and Cherbini, John and Johnson, Robert and Lyons, Andy and Kelly, Maggi},
  year = {2018},
  month = dec,
  volume = {2},
  pages = {39},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/drones2040039},
  abstract = {Remote sensing is important to precision agriculture and the spatial resolution provided by Unmanned Aerial Vehicles (UAVs) is revolutionizing precision agriculture workflows for measurement crop condition and yields over the growing season, for identifying and monitoring weeds and other applications. Monitoring of individual trees for growth, fruit production and pest and disease occurrence remains a high research priority and the delineation of each tree using automated means as an alternative to manual delineation would be useful for long-term farm management. In this paper, we detected citrus and other crop trees from UAV images using a simple convolutional neural network (CNN) algorithm, followed by a classification refinement using superpixels derived from a Simple Linear Iterative Clustering (SLIC) algorithm. The workflow performed well in a relatively complex agricultural environment (multiple targets, multiple size trees and ages, etc.) achieving high accuracy (overall accuracy = 96.24\%, Precision (positive predictive value) = 94.59\%, Recall (sensitivity) = 97.94\%). To our knowledge, this is the first time a CNN has been used with UAV multi-spectral imagery to focus on citrus trees. More of these individual cases are needed to develop standard automated workflows to help agricultural managers better incorporate large volumes of high resolution UAV imagery into agricultural management operations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/jbo/Zotero/storage/T7ZKVXX6/Csillik et al. - 2018 - Identification of Citrus Trees from Unmanned Aeria.pdf;/home/jbo/Zotero/storage/BC5YNIAJ/htm.html},
  journal = {Drones},
  keywords = {citrus,CNN,deep learning,feature extraction,precision agriculture,superpixels,tree identification,UAS},
  language = {en},
  number = {4}
}

@article{denker1988neural,
  title = {Neural {{Network Recognizer}} for {{Hand}}-{{Written Zip Code Digits}}},
  author = {Denker, John and Gardner, W. and Graf, Hans and Henderson, Donnie and Howard, R. and Hubbard, W. and Jackel, L. D. and Baird, Henry and Guyon, Isabelle},
  year = {1988},
  volume = {1},
  pages = {323--331},
  file = {/home/jbo/Zotero/storage/G6NS4T8R/Denker et al. - 1988 - Neural Network Recognizer for Hand-Written Zip Cod.pdf;/home/jbo/Zotero/storage/Q7JSFSKM/a97da629b098b75c294dffdc3e463904-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  language = {en}
}

@article{devries2017improved,
  title = {Improved {{Regularization}} of {{Convolutional Neural Networks}} with {{Cutout}}},
  author = {DeVries, Terrance and Taylor, Graham W.},
  year = {2017},
  month = nov,
  abstract = {Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56\%, 15.20\%, and 1.30\% test error respectively. Code is available at https://github.com/uoguelph-mlrg/Cutout},
  archiveprefix = {arXiv},
  eprint = {1708.04552},
  eprinttype = {arxiv},
  journal = {arXiv:1708.04552 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{dossantos2019assessment,
  title = {Assessment of {{CNN}}-{{Based Methods}} for {{Individual Tree Detection}} on {{Images Captured}} by {{RGB Cameras Attached}} to {{UAVs}}},
  author = {{dos Santos}, Anderson Aparecido and Marcato Junior, Jos{\'e} and Ara{\'u}jo, M{\'a}rcio Santos and Di Martini, David Robledo and Tetila, Everton Castel{\~a}o and Siqueira, Henrique Lopes and Aoki, Camila and Eltner, Anette and Matsubara, Edson Takashi and Pistori, Hemerson and Feitosa, Raul Queiroz and Liesenberg, Veraldo and Gon{\c c}alves, Wesley Nunes},
  year = {2019},
  month = aug,
  volume = {19},
  issn = {1424-8220},
  doi = {10.3390/s19163595},
  abstract = {Detection and classification of tree species from remote sensing data were performed using mainly multispectral and hyperspectral images and Light Detection And Ranging (LiDAR) data. Despite the comparatively lower cost and higher spatial resolution, few studies focused on images captured by Red-Green-Blue (RGB) sensors. Besides, the recent years have witnessed an impressive progress of deep learning methods for object detection. Motivated by this scenario, we proposed and evaluated the usage of Convolutional Neural Network (CNN)-based methods combined with Unmanned Aerial Vehicle (UAV) high spatial resolution RGB imagery for the detection of law protected tree species. Three state-of-the-art object detection methods were evaluated: Faster Region-based Convolutional Neural Network (Faster R-CNN), YOLOv3 and RetinaNet. A dataset was built to assess the selected methods, comprising 392 RBG images captured from August 2018 to February 2019, over a forested urban area in midwest Brazil. The target object is an important tree species threatened by extinction known as Dipteryx alata Vogel (Fabaceae). The experimental analysis delivered average precision around 92\% with an associated processing times below 30 miliseconds.},
  file = {/home/jbo/Zotero/storage/W4GLW8ID/dos Santos et al. - 2019 - Assessment of CNN-Based Methods for Individual Tre.pdf},
  journal = {Sensors (Basel, Switzerland)},
  number = {16},
  pmcid = {PMC6719170},
  pmid = {31426597}
}

@article{egli2020cnnbased,
  title = {{{CNN}}-{{Based Tree Species Classification Using High Resolution RGB Image Data}} from {{Automated UAV Observations}}},
  author = {Egli, Sebastian and H{\"o}pke, Martin},
  year = {2020},
  month = jan,
  volume = {12},
  pages = {3892},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/rs12233892},
  abstract = {Data on the distribution of tree species are often requested by forest managers, inventory agencies, foresters as well as private and municipal forest owners. However, the automated detection of tree species based on passive remote sensing data from aerial surveys is still not sufficiently developed to achieve reliable results independent of the phenological stage, time of day, season, tree vitality and prevailing atmospheric conditions. Here, we introduce a novel tree species classification approach based on high resolution RGB image data gathered during automated UAV flights that overcomes these insufficiencies. For the classification task, a computationally lightweight convolutional neural network (CNN) was designed. We show that with the chosen CNN model architecture, average classification accuracies of 92\% can be reached independently of the illumination conditions and the phenological stages of four different tree species. We also show that a minimal ground sampling density of 1.6 cm/px is needed for the classification model to be able to make use of the spatial-structural information in the data. Finally, to demonstrate the applicability of the presented approach to derive spatially explicit tree species information, a gridded product is generated that yields an average classification accuracy of 88\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/jbo/Zotero/storage/DS47HA7I/Egli and Höpke - 2020 - CNN-Based Tree Species Classification Using High R.pdf;/home/jbo/Zotero/storage/7P7SUS2N/3892.html},
  journal = {Remote Sensing},
  keywords = {CNN,RGB,tree species classification,UAV},
  language = {en},
  number = {23}
}

@article{fabijanska2018deepdendro,
  title = {{{DeepDendro}} \textendash{} {{A}} Tree Rings Detector Based on a Deep Convolutional Neural Network},
  author = {Fabija{\'n}ska, Anna and Danek, Ma{\l}gorzata},
  year = {2018},
  month = jul,
  volume = {150},
  pages = {353--363},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2018.05.005},
  abstract = {Tree-ring analysis is widely used in many different fields of science. Among others, information carried by annual tree rings allows determining the rates of environmental changes and the timing of events. The analysis of the tree rings requires prior detection of tree-ring boundaries which is traditionally performed manually with the use of stereoscope, a moving table, and a data recorder. This is, however, time-consuming and very cumbersome, especially in the case of long tree-ring series. Several approaches to an automatic detection of tree-ring boundaries exist; however, they use basic image processing techniques. As a result, their accuracy is limited, and their application is restricted mainly to conifer wood where the tree-ring boundaries are clearly defined. There also exists some commercial software, however, none of them is perfect as they fail when applied to the ring-porous wood type. Therefore this paper proposes a DeepDendro approach i.e., an automatic tree-ring boundary detector built upon the U-Net convolutional network. To the authors' best knowledge this is the first study which applies ConvNets for an automatic detection of tree rings. The performance of the existing approach was tested on the dataset of images of wood cores of three species that represent the ring-porous type of the anatomical structure (Quercus sp., Fraxinus excelsior L., and Ulmus sp.). The testing dataset contained over 2500 of tree-ring boundaries, 96\% of which were determined correctly by the proposed method. The corresponding precision is at the level of 0.97 which confirms that only a few false boundaries were introduced by the DeepDendro approach. The results were obtained automatically without any user interaction.},
  file = {/home/jbo/Zotero/storage/HMP2MW5V/S0168169918300413.html},
  journal = {Computers and Electronics in Agriculture},
  keywords = {Convolutional neural network,Deep learning,Dendrochronology,Tree rings detection,U-Net},
  language = {en}
}

@article{fricker2019convolutional,
  title = {A {{Convolutional Neural Network Classifier Identifies Tree Species}} in {{Mixed}}-{{Conifer Forest}} from {{Hyperspectral Imagery}}},
  author = {Fricker, Geoffrey A. and Ventura, Jonathan D. and Wolf, Jeffrey A. and North, Malcolm P. and Davis, Frank W. and Franklin, Janet},
  year = {2019},
  month = jan,
  volume = {11},
  pages = {2326},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/rs11192326},
  abstract = {In this study, we automate tree species classification and mapping using field-based training data, high spatial resolution airborne hyperspectral imagery, and a convolutional neural network classifier (CNN). We tested our methods by identifying seven dominant trees species as well as dead standing trees in a mixed-conifer forest in the Southern Sierra Nevada Mountains, CA (USA) using training, validation, and testing datasets composed of spatially-explicit transects and plots sampled across a single strip of imaging spectroscopy. We also used a three-band \&lsquo;Red-Green-Blue\&rsquo; pseudo true-color subset of the hyperspectral imagery strip to test the classification accuracy of a CNN model without the additional non-visible spectral data provided in the hyperspectral imagery. Our classifier is pixel-based rather than object based, although we use three-dimensional structural information from airborne Light Detection and Ranging (LiDAR) to identify trees (points \&gt; 5 m above the ground) and the classifier was applied to image pixels that were thus identified as tree crowns. By training a CNN classifier using field data and hyperspectral imagery, we were able to accurately identify tree species and predict their distribution, as well as the distribution of tree mortality, across the landscape. Using a window size of 15 pixels and eight hidden convolutional layers, a CNN model classified the correct species of 713 individual trees from hyperspectral imagery with an average F-score of 0.87 and F-scores ranging from 0.67\&ndash;0.95 depending on species. The CNN classification model performance increased from a combined F-score of 0.64 for the Red-Green-Blue model to a combined F-score of 0.87 for the hyperspectral model. The hyperspectral CNN model captures the species composition changes across \textasciitilde 700 meters (1935 to 2630 m) of elevation from a lower-elevation mixed oak conifer forest to a higher-elevation fir-dominated coniferous forest. High resolution tree species maps can support forest ecosystem monitoring and management, and identifying dead trees aids landscape assessment of forest mortality resulting from drought, insects and pathogens. We publicly provide our code to apply deep learning classifiers to tree species identification from geospatial imagery and field training data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/jbo/Zotero/storage/JXRVSF8D/Fricker et al. - 2019 - A Convolutional Neural Network Classifier Identifi.pdf;/home/jbo/Zotero/storage/WN9CTA72/2326.html},
  journal = {Remote Sensing},
  keywords = {convolutional neural networks,deep learning,hyperspectral imagery,species distribution modeling},
  language = {en},
  number = {19}
}

@article{fukushima1975cognitron,
  title = {Cognitron: {{A}} Self-Organizing Multilayered Neural Network},
  shorttitle = {Cognitron},
  author = {Fukushima, Kunihiko},
  year = {1975},
  month = sep,
  volume = {20},
  pages = {121--136},
  issn = {1432-0770},
  doi = {10.1007/BF00342633},
  abstract = {A new hypothesis for the organization of synapses between neurons is proposed: ``The synapse from neuron x to neuron y is reinforced when x fires provided that no neuron in the vicinity of y is firing stronger than y''. By introducing this hypothesis, a new algorithm with which a multilayered neural network is effectively organized can be deduced. A self-organizing multilayered neural network, which is named ``cognitron'', is constructed following this algorithm, and is simulated on a digital computer. Unlike the organization of a usual brain models such as a three-layered perceptron, the self-organization of a cognitron progresses favorably without having a ``teacher'' which instructs in all particulars how the individual cells respond. After repetitive presentations of several stimulus patterns, the cognitron is self-organized in such a way that the receptive fields of the cells become relatively larger in a deeper layer. Each cell in the final layer integrates the information from whole parts of the first layer and selectively responds to a specific stimulus pattern or a feature.},
  journal = {Biological Cybernetics},
  language = {en},
  number = {3}
}

@article{fukushima1980neocognitron,
  title = {Neocognitron: {{A}} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  year = {1980},
  month = apr,
  volume = {36},
  pages = {193--202},
  issn = {1432-0770},
  doi = {10.1007/BF00344251},
  abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by ``learning without a teacher'', and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname ``neocognitron''. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of ``S-cells'', which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of ``C-cells'' similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any ``teacher'' during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
  journal = {Biological Cybernetics},
  language = {en},
  number = {4}
}

@inproceedings{fukushima1982neocognitron,
  title = {Neocognitron: {{A Self}}-{{Organizing Neural Network Model}} for a {{Mechanism}} of {{Visual Pattern Recognition}}},
  shorttitle = {Neocognitron},
  booktitle = {Competition and {{Cooperation}} in {{Neural Nets}}},
  author = {Fukushima, Kunihiko and Miyake, Sei},
  editor = {Amari, Shun-ichi and Arbib, Michael A.},
  year = {1982},
  pages = {267--285},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-46466-9_18},
  abstract = {A neural network model, called a ``neocognitron'', is proposed for a mechanism of visual pattern recognition. It is demonstrated by computer simulation that the neocognitron has characteristics similar to those of visual systems of vertebrates.The neocognitron is a multilayered network consisting of a cascade connection of many layers of cells, and the efficiencies of the synaptic connections between cells are modifiable. Self-organization of the network progresses by means of ``learning-without-a-teacher'' process: Only repetitive presentation of a set of stimulus patterns is necessary for the self-organization of the network, and no information about the categories to which these patterns should be classified is needed. The neocognitron by itself acquires the ability to classify and correctly recognize these patterns according to the differences in their shapes: Any patterns which we human beings judge to be alike are also judged to be of the same category by the neocognitron. The neocognitron recognizes stimulus patterns correctly without being affected by shifts in position or even by considerable distortions in shape of the stimulus patterns. If a stimulus pattern is presented at a different position or if the shape of the pattern is distorted, the responses of the cells in the intermediate layers, especially the ones near the input layer, vary with the shift in position or the distortion in shape of the pattern. However, the deeper the layer is, the smaller become the variations in cellular responses. Thus, the cells of the deepest layer of the network are not affected by the shift in position or the distortion in shape of the stimulus pattern.},
  isbn = {978-3-642-46466-9},
  keywords = {Hierarchical Model,Input Layer,Neural Network Model,Receptive Field,Synaptic Connection},
  language = {en},
  series = {Lecture {{Notes}} in {{Biomathematics}}}
}

@article{fukushima1988neocognitron,
  title = {Neocognitron: {{A}} Hierarchical Neural Network Capable of Visual Pattern Recognition},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  year = {1988},
  month = jan,
  volume = {1},
  pages = {119--130},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(88)90014-7},
  abstract = {A neural network model for visual pattern recognition, called the ``neocognitron,'' was previously proposed by the author. In this paper, we discuss the mechanism of the model in detail. In order to demonstrate the ability of the neocognitron, we also discuss a pattern-recognition system which works with the mechanism of the neocognitron. The system has been implemented on a minicomputer and has been trained to recognize handwritten numerals. The neocognitron is a hierarchical network consisting of many layers of cells, and has variable connections between the cells in adjoining layers. It can acquire the ability to recognize patterns by learning, and can be trained to recognize any set of patterns. After finishing the process of learning, pattern recognition is performed on the basis of similarity in shape between patterns, and is not affected by deformation, nor by changes in size, nor by shifts in the position of the input patterns. In the hierarchical network of the neocognitron, local features of the input pattern are extracted by the cells of a lower stage, and they are gradually integrated into more global features. Finally, each cell of the highest stage integrates all the information of the input pattern, and responds only to one specific pattern. Thus, the response of the cells of the highest stage shows the final result of the pattern-recognition of the network. During this process of extracting and integrating features, errors in the relative position of local features are gradually tolerated. The operation of tolerating positional error a little at a time at each stage, rather than all in one step, plays an important role in endowing the network with an ability to recognize even distorted patterns.},
  file = {/home/jbo/Zotero/storage/I8EQJ2WT/0893608088900147.html},
  journal = {Neural Networks},
  language = {en},
  number = {2}
}

@article{g.braga2020tree,
  title = {Tree {{Crown Delineation Algorithm Based}} on a {{Convolutional Neural Network}}},
  author = {G. Braga, Jos{\'e} R. and Peripato, Vin{\'i}cius and Dalagnol, Ricardo and P. Ferreira, Matheus and Tarabalka, Yuliya and O. C. Arag{\~a}o, Luiz E. and {F. de Campos Velho}, Haroldo and Shiguemori, Elcio H. and Wagner, Fabien H.},
  year = {2020},
  month = jan,
  volume = {12},
  pages = {1288},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/rs12081288},
  abstract = {Tropical forests concentrate the largest diversity of species on the planet and play a key role in maintaining environmental processes. Due to the importance of those forests, there is growing interest in mapping their components and getting information at an individual tree level to conduct reliable satellite-based forest inventory for biomass and species distribution qualification. Individual tree crown information could be manually gathered from high resolution satellite images; however, to achieve this task at large-scale, an algorithm to identify and delineate each tree crown individually, with high accuracy, is a prerequisite. In this study, we propose the application of a convolutional neural network\&mdash;Mask R-CNN algorithm\&mdash;to perform the tree crown detection and delineation. The algorithm uses very high-resolution satellite images from tropical forests. The results obtained are promising\&mdash;the     R e c a l l    ,     P r e c i s i o n    , and     F 1     score values obtained were were     0.81    ,     0.91    , and     0.86    , respectively. In the study site, the total of tree crowns delineated was     59,062    . These results suggest that this algorithm can be used to assist the planning and conduction of forest inventories. As the algorithm is based on a Deep Learning approach, it can be systematically trained and used for other regions.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/jbo/Zotero/storage/CATD7A9Z/G. Braga et al. - 2020 - Tree Crown Delineation Algorithm Based on a Convol.pdf;/home/jbo/Zotero/storage/3CGSKS8W/1288.html},
  journal = {Remote Sensing},
  keywords = {deep learning,optical satellite images,tree crown delineation,tropical forests},
  language = {en},
  number = {8}
}

@article{gao2016degrees,
  title = {Degrees of {{Freedom}} in {{Deep Neural Networks}}},
  author = {Gao, Tianxiang and Jojic, Vladimir},
  year = {2016},
  month = jun,
  abstract = {In this paper, we explore degrees of freedom in deep sigmoidal neural networks. We show that the degrees of freedom in these models are related to the expected optimism, which is the expected difference between test error and training error. We provide an efficient Monte-Carlo method to estimate the degrees of freedom for multi-class classification methods. We show that the degrees of freedom is less than the parameter count in a simple XOR network. We extend these results to neural nets trained on synthetic and real data and investigate the impact of network's architecture and different regularization choices. The degrees of freedom in deep networks is dramatically less than the number of parameters. In some real datasets, the number of parameters is several orders of magnitude larger than the degrees of freedom. Further, we observe that for fixed number of parameters, deeper networks have less degrees of freedom exhibiting a regularization-by-depth. Finally, we show that the degrees of freedom of deep neural networks can be used in a model selection criterion. This criterion has comparable performance to crossvalidation with lower computational cost.},
  archiveprefix = {arXiv},
  eprint = {1603.09260},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/D2S64IFB/Gao and Jojic - 2016 - Degrees of Freedom in Deep Neural Networks.pdf},
  journal = {arXiv:1603.09260 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@inproceedings{giebel1971feature,
  title = {Feature {{Extraction}} and {{Recognition}} of {{Handwritten Characters}} by {{Homogeneous Layers}}},
  booktitle = {Zeichenerkennung Durch Biologische Und Technische {{Systeme}} / {{Pattern Recognition}} in {{Biological}} and {{Technical Systems}}},
  author = {Giebel, H.},
  editor = {Gr{\"u}sser, Otto-Joachim and Klinke, Rainer},
  year = {1971},
  pages = {162--169},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-65175-5_15},
  abstract = {Artificial systems for solving difficult problems of pattern recognition are still very inefficient compared to the human visual system \textemdash{} at least if we regard the error rate. On the other hand characters are formed in such a manner that they can be easily distinguished by the human visual system which defines their meaning. It is not necessary that an artificial recognition system is constructed in the same way as neuronal systems; but if it is based on the same principles of perception \textemdash{} as far as they are known \textemdash{} it might have a better chance of performing the same recognition operation.},
  isbn = {978-3-642-65175-5},
  language = {en}
}

@inproceedings{glorot2011deep,
  title = {Deep {{Sparse Rectifier Neural Networks}}},
  booktitle = {Proceedings of the {{Fourteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  year = {2011},
  month = jun,
  pages = {315--323},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neu...},
  file = {/home/jbo/Zotero/storage/THVUG26H/Glorot et al. - 2011 - Deep Sparse Rectifier Neural Networks.pdf;/home/jbo/Zotero/storage/H4QT8JFV/glorot11a.html},
  language = {en}
}

@techreport{goodfellow2020best,
  title = {Best {{Management Practices}} - {{Utility Tree Risk Assessment}}},
  author = {Goodfellow, John W.},
  year = {2020},
  pages = {95},
  institution = {{International Society of Arboriculture}},
  file = {/home/jbo/Zotero/storage/PKTU5QMP/4430.html},
  number = {P1321}
}

@article{graziano2020wider,
  title = {The Wider Regional Benefits of Power Grids Improved Resilience through Tree-Trimming Operations Evidences from {{Connecticut}}, {{USA}}},
  author = {Graziano, Marcello and Gunther, Peter and Gallaher, Adam and Carstensen, Fred V. and Becker, Brian},
  year = {2020},
  month = mar,
  volume = {138},
  pages = {111293},
  issn = {0301-4215},
  doi = {10.1016/j.enpol.2020.111293},
  abstract = {Tree-trimming operations (TTOs) are expensive, yet popular management practices for increasing power-grid reliability. In this work, we investigate and identify the relationship between TTOs and power outages and quantify the regional economic benefits TTOs provide in the three years following these operations. Our data focus on a portion of Connecticut, for 2009\textendash 2015. We find that even a limited application of TTOs reduce outages substantially. We combine this result with an advanced economic model to estimate the benefits to the state. We find that this reduction in outages translates in to considerable savings for the state's economy, justifying expansion of TTOs.},
  file = {/home/jbo/Zotero/storage/JMVKTB7S/S0301421520300513.html},
  journal = {Energy Policy},
  keywords = {Economic modelling,Electricity,Outages,REMI,Trimming,Vegetation management},
  language = {en}
}

@article{gu2018recent,
  title = {Recent Advances in Convolutional Neural Networks},
  author = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
  year = {2018},
  month = may,
  volume = {77},
  pages = {354--377},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2017.10.013},
  abstract = {In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.},
  journal = {Pattern Recognition},
  keywords = {Convolutional neural network,Deep learning},
  language = {en}
}

@article{gu2018recenta,
  title = {Recent Advances in Convolutional Neural Networks},
  author = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
  year = {2018},
  month = may,
  volume = {77},
  pages = {354--377},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2017.10.013},
  abstract = {In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.},
  journal = {Pattern Recognition},
  keywords = {Convolutional neural network,Deep learning},
  language = {en}
}

@article{guggenmoos2003effects,
  title = {{{EFFECTS OF TREE MORTALITY ON POWER LINE SECURITY}}},
  author = {Guggenmoos, Siegfried},
  year = {2003},
  volume = {29},
  pages = {181--196},
  abstract = {Others have reported that instances where trees grow into lines rarely result in power outages. The vast majority of tree-related outages stem from tree failure, particularly if outages during severe weather events are included. Generally, tree\textendash conductor conflicts resulting from tree failure are classified as unpreventable because the trees are located outside the right-of-way. In the emerging competitive environment, utilities will require a means of decreasing so-called unpreventable outages. The primary locations for unpreventable outages are areas where lines run adjacent to or through natural forest tree stands. Tree mortality exposes a power line to a high risk of tree incidents over time. The risk to the line is directly related to the number of trees within striking distance of the line. Conventional clear widths leave a substantial residual tree risk. Hazard tree removal programs do not provide enduring reliability gains. A new mathematical model, the optimal clear width calculator, is used to assess the tree risk over variable clear widths and line heights. The risk ratings in the output line strike probability charts permit quantitative comparisons of construction and maintenance options. The line strike probability chart indicates that there is a point of diminishing return in line security for dollars invested in additional clear width.},
  file = {/home/jbo/Zotero/storage/PV6ADAP5/Guggenmoos - 2003 - EFFECTS OF TREE MORTALITY ON POWER LINE SECURITY.pdf},
  journal = {Journal of Arboriculture},
  language = {en},
  number = {4}
}

@article{guggenmoos2011treerelated,
  title = {Tree-Related {{Electric Outages Due To Wind Loading}}},
  author = {Guggenmoos, Siegfried},
  year = {2011},
  volume = {37},
  pages = {147--151},
  abstract = {In the aftermath of a wind storm that interrupted service on more than 40\% of Puget Sound Energy's transmission system, the regulator ordered an investigation to evaluate options for hardening the electric system. The initial phase of the study quantified the extent of tree exposure along the transmission system and examined the correlation between various field measurable variables and tree-caused outage frequency. This phase of the work correlated 10 years of wind data with 10 years of outage data. Tree failure rates were calculated and used to model tree-caused outage expectations based on wind speed. Models were developed to assess the outage impact of interventions that reduce the transmission system exposure to trees.},
  file = {/home/jbo/Zotero/storage/TXCS9BAE/Guggenmoos - 2011 - Tree-related Electric Outages Due To Wind Loading.pdf},
  journal = {Arboriculture and Urban Forestry},
  language = {en},
  number = {4}
}

@article{guikema2006statistical,
  title = {Statistical Models of the Effects of Tree Trimming on Power System Outages},
  author = {Guikema, S. D. and Davidson, R. A. and {Haibin Liu}},
  year = {2006},
  month = jul,
  volume = {21},
  pages = {1549--1557},
  issn = {1937-4208},
  doi = {10.1109/TPWRD.2005.860238},
  abstract = {This paper develops statistical models for estimating the impacts of tree trimming on electric power system outages under normal (nonstorm) operating conditions. The models are based on an extensive data set from Duke Power, a company in the southeastern U.S., and the models used are a negative binomial generalized linear model and a Poisson generalized linear mixed model (GLMM). The results show that: 1) increasing tree trimming frequency does lead to a decrease in the number of outages on the electric power distribution system; 2) the effects of tree trimming on different circuits can be differentiated and measured; and 3) the Poisson GLMM provides a good fit to the data in this situation. In particular, the results of the model show that for the Duke Power system, one would have expected, on average, 0.9 fewer outages per circuit over the 43-month data recording period if the time between tree trimming cycles was decreased by 1 yr across the whole system. These models could be applied to other power systems, and the results should be useful for power managers in setting tree trimming frequencies and in focusing on the most frequent trimming efforts on those circuits for which trimming will have the greatest benefit.},
  file = {/home/jbo/Zotero/storage/MPFQ34S5/1645199.html},
  journal = {IEEE Transactions on Power Delivery},
  keywords = {binomial generalized linear model,Circuits,data recording,Duke Power data set,electric power distribution systems,electric power system outages,Electric variables measurement,Frequency measurement,Maintenance,Poisson equation,Poisson generalized linear mixed model,Power distribution maintenance,power distribution reliability,Power measurement,Power system management,Power system measurements,Power system modeling,Power system reliability,Reliability engineering,statistical analysis,statistical models,statistics,tree trimming effects,vegetation},
  number = {3}
}

@article{he2015deep,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/3X5LLNZQ/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/home/jbo/Zotero/storage/VRV9XQ89/1512.html},
  journal = {arXiv:1512.03385 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{hubel1959receptive,
  title = {Receptive Fields of Single Neurones in the Cat's Striate Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  year = {1959},
  month = oct,
  volume = {148},
  pages = {574--591},
  issn = {0022-3751},
  file = {/home/jbo/Zotero/storage/4T9ULWVN/Hubel and Wiesel - 1959 - Receptive fields of single neurones in the cat's s.pdf},
  journal = {The Journal of Physiology},
  number = {3},
  pmcid = {PMC1363130},
  pmid = {14403679}
}

@article{hubel1962receptive,
  title = {Receptive Fields, Binocular Interaction and Functional Architecture in the Cat's Visual Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  year = {1962},
  month = jan,
  volume = {160},
  pages = {106-154.2},
  issn = {0022-3751},
  abstract = {Images null},
  file = {/home/jbo/Zotero/storage/TZSF52DN/Hubel and Wiesel - 1962 - Receptive fields, binocular interaction and functi.pdf},
  journal = {The Journal of Physiology},
  number = {1},
  pmcid = {PMC1359523},
  pmid = {14449617}
}

@article{hubel1965receptive,
  title = {Receptive Fields and Functional Architecture in Two Nonstriate Visual Areas (18 and 19) of the Cat},
  author = {Hubel, David H. and Wiesel, Torsten N.},
  year = {1965},
  month = mar,
  volume = {28},
  pages = {229--289},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.1965.28.2.229},
  file = {/home/jbo/Zotero/storage/7VXXXSYC/Hubel and Wiesel - 1965 - Receptive fields and functional architecture in tw.pdf;/home/jbo/Zotero/storage/59ZEF5UD/jn.1965.28.2.html},
  journal = {Journal of Neurophysiology},
  number = {2}
}

@article{hubel1968receptive,
  title = {Receptive Fields and Functional Architecture of Monkey Striate Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  year = {1968},
  volume = {195},
  pages = {215--243},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.1968.sp008455},
  abstract = {1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded. 2. Evidence is presented for at least two independent systems of columns extending vertically from surface to white matter. Columns of the first type contain cells with common receptive-field orientations. They are similar to the orientation columns described in the cat, but are probably smaller in cross-sectional area. In the second system cells are aggregated into columns according to eye preference. The ocular dominance columns are larger than the orientation columns, and the two sets of boundaries seem to be independent. 3. There is a tendency for cells to be grouped according to symmetry of responses to movement; in some regions the cells respond equally well to the two opposite directions of movement of a line, but other regions contain a mixture of cells favouring one direction and cells favouring the other. 4. A horizontal organization corresponding to the cortical layering can also be discerned. The upper layers (II and the upper two-thirds of III) contain complex and hypercomplex cells, but simple cells are virtually absent. The cells are mostly binocularly driven. Simple cells are found deep in layer III, and in IV A and IV B. In layer IV B they form a large proportion of the population, whereas complex cells are rare. In layers IV A and IV B one finds units lacking orientation specificity; it is not clear whether these are cell bodies or axons of geniculate cells. In layer IV most cells are driven by one eye only; this layer consists of a mosaic with cells of some regions responding to one eye only, those of other regions responding to the other eye. Layers V and VI contain mostly complex and hypercomplex cells, binocularly driven. 5. The cortex is seen as a system organized vertically and horizontally in entirely different ways. In the vertical system (in which cells lying along a vertical line in the cortex have common features) stimulus dimensions such as retinal position, line orientation, ocular dominance, and perhaps directionality of movement, are mapped in sets of superimposed but independent mosaics. The horizontal system segregates cells in layers by hierarchical orders, the lowest orders (simple cells monocularly driven) located in and near layer IV, the higher orders in the upper and lower layers.},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1968.sp008455},
  copyright = {\textcopyright{} 1968 The Physiological Society},
  file = {/home/jbo/Zotero/storage/4GIVRRBT/Hubel and Wiesel - 1968 - Receptive fields and functional architecture of mo.pdf;/home/jbo/Zotero/storage/CIUE2CJL/jphysiol.1968.html},
  journal = {The Journal of Physiology},
  language = {en},
  number = {1}
}

@article{ioffe2015batch,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  year = {2015},
  month = mar,
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  archiveprefix = {arXiv},
  eprint = {1502.03167},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/8GY8YVGG/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;/home/jbo/Zotero/storage/7LEIJRJN/1502.html},
  journal = {arXiv:1502.03167 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{jiao2020artificial,
  title = {Artificial Intelligence in Seismology: {{Advent}}, Performance and Future Trends},
  shorttitle = {Artificial Intelligence in Seismology},
  author = {Jiao, Pengcheng and Alavi, Amir H.},
  year = {2020},
  month = may,
  volume = {11},
  pages = {739--744},
  issn = {1674-9871},
  doi = {10.1016/j.gsf.2019.10.004},
  abstract = {Realistically predicting earthquake is critical for seismic risk assessment, prevention and safe design of major structures. Due to the complex nature of seismic events, it is challengeable to efficiently identify the earthquake response and extract indicative features from the continuously detected seismic data. These challenges severely impact the performance of traditional seismic prediction models and obstacle the development of seismology in general. Taking their advantages in data analysis, artificial intelligence (AI) techniques have been utilized as powerful statistical tools to tackle these issues. This typically involves processing massive detected data with severe noise to enhance the seismic performance of structures. From extracting meaningful sensing data to unveiling seismic events that are below the detection level, AI assists in identifying unknown features to more accurately predicting the earthquake activities. In this focus paper, we provide an overview of the recent AI studies in seismology and evaluate the performance of the major AI techniques including machine learning and deep learning in seismic data analysis. Furthermore, we envision the future direction of the AI methods in earthquake engineering which will involve deep learning-enhanced seismology in an internet-of-things (IoT) platform.},
  file = {/home/jbo/Zotero/storage/9SXGA2SK/Jiao and Alavi - 2020 - Artificial intelligence in seismology Advent, per.pdf;/home/jbo/Zotero/storage/HNE9ZQZM/S1674987119301987.html},
  journal = {Geoscience Frontiers},
  keywords = {Artificial intelligence,Deep learning,Internet-of-Things,Machine learning,Seismology},
  language = {en},
  number = {3}
}

@book{kabrisky1966proposed,
  title = {A {{Proposed Model}} for {{Visual Information Processing}} in the {{Human Brain}}},
  author = {Kabrisky, Matthew},
  year = {1966},
  publisher = {{University of Illinois Press}},
  googlebooks = {jPVqAAAAMAAJ},
  isbn = {978-0-252-72727-6},
  language = {en}
}

@article{kingma2017adam,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/Q89FVSJD/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/home/jbo/Zotero/storage/RYRYCUE7/1412.html},
  journal = {arXiv:1412.6980 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{koeser2016frequency,
  title = {Frequency, Severity, and Detectability of Internal Trunk Decay of Street Tree {{Quercus}} Spp. in {{Tampa}}, {{Florida}}, {{U}}.{{S}}.},
  author = {Koeser, A. K. and McLean, D. C. and Hasing, G. and Allison, R. B.},
  year = {2016},
  volume = {42},
  pages = {217--226},
  publisher = {{International Society of Arboriculture}},
  issn = {1935-5297},
  abstract = {Wood decay is a factor considered in all commonly accepted tree risk assessment methods; however, few studies have attempted to assess its presence in the urban forest or its predictability given visual cues and site factors. A random sampling of trees situated on hurricane evacuation routes was inventoried and assessed for risk in the city of Tampa, Florida, U.S. In addition to a basic visual...},
  file = {/home/jbo/Zotero/storage/Q92JIUET/www.cabdirect.org.html},
  journal = {Arboriculture \&amp; Urban Forestry},
  language = {English},
  number = {4}
}

@article{koeser2020can,
  title = {Can Professionals Gauge Likelihood of Failure? \textendash{} {{Insights}} from Tropical Storm {{Matthew}}},
  shorttitle = {Can Professionals Gauge Likelihood of Failure?},
  author = {Koeser, Andrew K. and Thomas Smiley, E. and Hauer, Richard J. and Kane, Brian and Klein, Ryan W. and Landry, Shawn M. and Sherwood, Michael},
  year = {2020},
  month = jun,
  volume = {52},
  pages = {126701},
  issn = {1618-8667},
  doi = {10.1016/j.ufug.2020.126701},
  abstract = {Visual risk assessment remains the primary means of gauging urban tree safety and is a key facet of storm preparation and response. While past research has investigated the reproducibility of risk assessment methodologies (i.e., precision), few, if any, studies truly address the accuracy of current inspection practices \textendash{} especially with regard to the characterization of likelihood of failure. In 2016, Hurricane Matthew made landfall in the Southeastern United States as a lower-intensity tropical storm, impacting several urban sites where tree risk assessments had been conducted in the recent past. After the storm, 2069 trees on 5 properties were revisited to assess storm damage. The vast majority (93\%) of trees survived Matthew intact, with 6\% of the assessed population suffering partial (i.e., branch) failure and the remaining 1\% experiencing whole-tree failure. Failure rates differed by species, with age, and given the presence of external defects. The presence of dead branches (P-value {$<$} 0.001), deep planting (P-value {$<$} 0.001), severe stem-girdling roots (P-value = 0.020), and previous wounding (P-value = 0.016) were associated with increased likelihood of failure. The original risk assessments were fairly accurate: 94.1\% of trees assessed as having an ``imminent'' likelihood of failure were damaged in the storm. In contrast, 38.8\% of trees rated as ``probable'', 15.3\% of tree rated ``possible'', 0.0\% of trees rated ``improbable'' with regard to likelihood of failure were damaged during the storm.},
  journal = {Urban Forestry \& Urban Greening},
  keywords = {Arboriculture,Basic tree assessment,Hazard tree,Level 2 assessment,Natural disasters,Qualifications,Risk management,Storm damage,Urban forestry,Visual tree assessment},
  language = {en}
}

@article{krizhevsky2012imageneta,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  year = {2012},
  volume = {25},
  pages = {1097--1105},
  file = {/home/jbo/Zotero/storage/EMTQ39NM/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf;/home/jbo/Zotero/storage/DWLCVB2S/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  language = {en}
}

@inproceedings{lecun1989handwritten,
  title = {Handwritten {{Digit Recognition}} with a {{Back}}-{{Propagation Network}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 2},
  author = {LeCun, Yann and Boser, Bernhard E and Denker, John S and Henderson, Donnie and Howard, R E and Hubbard, Wayne E and Jackel, Lawrence D},
  year = {1989},
  pages = {9},
  abstract = {We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1\% error rate and about a 9\% reject rate on zipcode digits provided by the U.S. Postal Service.},
  file = {/home/jbo/Zotero/storage/4YQC7534/LeCun et al. - Handwritten Digit Recognition with a Back-Propagat.pdf},
  language = {en}
}

@article{lecun1998gradientbased,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {1998},
  month = nov,
  volume = {86},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  file = {/home/jbo/Zotero/storage/ZIQBSWPQ/Lecun et al. - 1998 - Gradient-based learning applied to document recogn.pdf;/home/jbo/Zotero/storage/7HAUSLBR/726791.html},
  journal = {Proceedings of the IEEE},
  keywords = {2D shape variability,back-propagation,backpropagation,Character recognition,cheque reading,complex decision surface synthesis,convolution,convolutional neural network character recognizers,document recognition,document recognition systems,Feature extraction,field extraction,gradient based learning technique,gradient-based learning,graph transformer networks,GTN,handwritten character recognition,handwritten digit recognition task,Hidden Markov models,high-dimensional patterns,language modeling,Machine learning,Multi-layer neural network,multilayer neural networks,multilayer perceptrons,multimodule systems,Neural networks,optical character recognition,Optical character recognition software,Optical computing,Pattern recognition,performance measure minimization,Principal component analysis,segmentation recognition},
  number = {11}
}

@article{li2018hyperband,
  title = {Hyperband: {{A Novel Bandit}}-{{Based Approach}} to {{Hyperparameter Optimization}}},
  shorttitle = {Hyperband},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year = {2018},
  volume = {18},
  pages = {1--52},
  issn = {1533-7928},
  file = {/home/jbo/Zotero/storage/M924TWX7/Li et al. - 2018 - Hyperband A Novel Bandit-Based Approach to Hyperp.pdf;/home/jbo/Zotero/storage/287Q45EG/16-558.html},
  journal = {Journal of Machine Learning Research},
  number = {185}
}

@article{nateghi2014power,
  title = {Power {{Outage Estimation}} for {{Tropical Cyclones}}: {{Improved Accuracy}} with {{Simpler Models}}},
  shorttitle = {Power {{Outage Estimation}} for {{Tropical Cyclones}}},
  author = {Nateghi, Roshanak and Guikema, Seth and Quiring, Steven M.},
  year = {2014},
  volume = {34},
  pages = {1069--1078},
  issn = {1539-6924},
  doi = {10.1111/risa.12131},
  abstract = {In this article, we discuss an outage-forecasting model that we have developed. This model uses very few input variables to estimate hurricane-induced outages prior to landfall with great predictive accuracy. We also show the results for a series of simpler models that use only publicly available data and can still estimate outages with reasonable accuracy. The intended users of these models are emergency response planners within power utilities and related government agencies. We developed our models based on the method of random forest, using data from a power distribution system serving two states in the Gulf Coast region of the United States. We also show that estimates of system reliability based on wind speed alone are not sufficient for adequately capturing the reliability of system components. We demonstrate that a multivariate approach can produce more accurate power outage predictions.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/risa.12131},
  copyright = {\textcopyright{} 2013 Society for Risk Analysis},
  file = {/home/jbo/Zotero/storage/W7SKCUSK/risa.html},
  journal = {Risk Analysis},
  keywords = {Data mining,hurricanes,power outage predictions,reliability},
  language = {en},
  number = {6}
}

@inproceedings{p2018cnn,
  title = {{{CNN Based Technique}} for {{Automatic Tree Counting Using Very High Resolution Data}}},
  booktitle = {2018 {{International Conference}} on {{Design Innovations}} for {{3Cs Compute Communicate Control}} ({{ICDI3C}})},
  author = {P, A. and Hebbar, R. and M.P, H. and Sounder, H. and K, N. and Vinod, P. V.},
  year = {2018},
  month = apr,
  pages = {127--129},
  doi = {10.1109/ICDI3C.2018.00036},
  abstract = {Coconut is one of the economically grown crops in India. In this paper, we develop an automatic method for counting the number of coconut trees in UAV images. The availability of high resolution remote sensing images helps people in having large amounts of detailed digital imaging of vegetation areas. Today, the estimated coconut tree count can be determined in a short duration of time through high resolution drone images with low cost and labor. The goal is to find new methods to determine coconut trees using remote sensing. Deep learning techniques with convolutional neural network (CNN) algorithms is used to detect the coconut trees.},
  file = {/home/jbo/Zotero/storage/4ZGUT3FS/8437104.html},
  keywords = {automatic method,automatic tree counting,Automatic; UAV; Remote sensing; Deep learning; CNN,CNN based technique,Convolution,convolutional neural network algorithms,Convolutional neural networks,crops,deep learning techniques,detailed digital imaging,Drones,economically grown crops,estimated coconut tree count,geophysical image processing,geophysical techniques,high resolution data,high resolution drone images,high resolution remote sensing images,image resolution,Image resolution,India,neural nets,Satellites,Training,UAV images,Vegetation,vegetation areas,vegetation mapping}
}

@article{parent2019analysis,
  title = {An Analysis of Enhanced Tree Trimming Effectiveness on Reducing Power Outages},
  author = {Parent, Jason R. and Meyer, Thomas H. and Volin, John C. and Fahey, Robert T. and Witharana, Chandi},
  year = {2019},
  month = jul,
  volume = {241},
  pages = {397--406},
  issn = {0301-4797},
  doi = {10.1016/j.jenvman.2019.04.027},
  abstract = {We evaluated the effectiveness of an enhanced tree trimming (ETT) program for its ability to reduce tree-related power outages, and thereby improve resilience, on an electric utility distribution system during storm events. Evaluations encompassed thirteen years of trimming (i.e. 2005\textendash 2017) data and were performed for both backbone and lateral utility lines. Backbones included all three phase lines between a substation and a faultable device whereas all other lines were considered laterals. The study site spanned the entire state of Connecticut, where the dominant vegetation is temperate deciduous forest. We controlled for variations in weather, tree cover, and wire type, by pairing ETT-treated zones with nearby untreated zones. ETT-treated conductors had storm outage rates that were 0.07\textendash 0.36 outages/km/year lower than untreated conductors or 35\textendash 180\% lower than the service-area's average annual outage rate for untreated conductors. ETT-treatment was associated with lower outage rates for ``minor'' outage types (i.e., blown fuse, tripped recloser, etc.) but the treatment effect was not statistically significant for ``major'' outage types (damaged poles or wires). System-wide ETT application, for the approximately 27,000 km of conductors in the study area, was predicted to reduce annual storm-related outages by an average of 81\textendash 104 and 318\textendash 759 outages/year for backbone and lateral lines, respectively. Our study provided a robust empirical evaluation of ETT and also proposes a geospatial methodology that controls for variations in weather and environment.},
  file = {/home/jbo/Zotero/storage/5H5NLBPL/S0301479719304840.html},
  journal = {Journal of Environmental Management},
  keywords = {Electric utility,Outage,Power distribution,Resilience,Tree trimming,Vegetation management},
  language = {en}
}

@article{rooney2005reliability,
  title = {{{THE RELIABILITY OF A WINDSHIELD SURVEY TO LOCATE HAZARDS IN ROADSIDE TREES}}},
  author = {Rooney, C. J. and Ryan, H. D. and Bloniarz, David V. and Kane, B.},
  year = {2005},
  volume = {31},
  abstract = {Hazardous conditions in roadside trees are a constant concern for municipal arborists. Due to fiscal constraints, many municipalities desire an accurate and efficient method to inspect their tree populations. This case study shows that a windshield survey can be used to find hazardous conditions in roadside trees, using a simple system and an experienced Certified Arborist. In addition, the case study showed that the percentage of detected hazardous conditions increased as the conditions became more severe. The percentage of hazardous tree conditions found using a windshield survey in developed sample areas far exceeded those found in undeveloped sample areas.},
  file = {/home/jbo/Zotero/storage/9R32VMM4/bc0e4bfb8b6c135475afc6cf968b77630d0e4f63.html},
  journal = {Journal of Arboriculture},
  language = {en},
  number = {2}
}

@book{rosenblatt1962principles,
  title = {Principles of Neurodynamics; Perceptrons and the Theory of Brain Mechanisms.},
  author = {Rosenblatt, Frank.},
  year = {1962},
  publisher = {{Spartan Books}},
  address = {{Washington}},
  file = {/home/jbo/Zotero/storage/EC2AZLKE/000203591.html},
  keywords = {Brain,Mathematical models.,Perceptrons}
}

@article{salehi2018emerging,
  title = {Emerging Artificial Intelligence Methods in Structural Engineering},
  author = {Salehi, Hadi and Burgue{\~n}o, Rigoberto},
  year = {2018},
  month = sep,
  volume = {171},
  pages = {170--189},
  issn = {0141-0296},
  doi = {10.1016/j.engstruct.2018.05.084},
  abstract = {Artificial intelligence (AI) is proving to be an efficient alternative approach to classical modeling techniques. AI refers to the branch of computer science that develops machines and software with human-like intelligence. Compared to traditional methods, AI offers advantages to deal with problems associated with uncertainties and is an effective aid to solve such complex problems. In addition, AI-based solutions are good alternatives to determine engineering design parameters when testing is not possible, thus resulting in significant savings in terms of human time and effort spent in experiments. AI is also able to make the process of decision making faster, decrease error rates, and increase computational efficiency. Among the different AI techniques, machine learning (ML), pattern recognition (PR), and deep learning (DL) have recently acquired considerable attention and are establishing themselves as a new class of intelligent methods for use in structural engineering. The objective of this review paper is to summarize techniques concerning applications of the noted AI methods in structural engineering developed over the last decade. First, a general introduction to AI is presented and the importance of AI in structural engineering is described. Thereafter, a review of recent applications of ML, PR, and DL in the field is provided, and the capability of such methods to address the restrictions of conventional models are discussed. Further, the advantages of employing such algorithmic methods are discussed in detail. Finally, potential research avenues and emerging trends for employing ML, PR, and DL are presented, and their limitations are discussed.},
  file = {/home/jbo/Zotero/storage/PFEPLZ98/S0141029617335526.html},
  journal = {Engineering Structures},
  keywords = {Artificial intelligence,Deep learning,Machine learning,Pattern recognition,Soft computing,Structural engineering},
  language = {en}
}

@article{santos2019assessment,
  title = {Assessment of {{CNN}}-{{Based Methods}} for {{Individual Tree Detection}} on {{Images Captured}} by {{RGB Cameras Attached}} to {{UAVs}}},
  author = {dos Santos, Anderson Aparecido and Marcato Junior, Jos{\'e} and Ara{\'u}jo, M{\'a}rcio Santos and Di Martini, David Robledo and Tetila, Everton Castel{\~a}o and Siqueira, Henrique Lopes and Aoki, Camila and Eltner, Anette and Matsubara, Edson Takashi and Pistori, Hemerson and Feitosa, Raul Queiroz and Liesenberg, Veraldo and Gon{\c c}alves, Wesley Nunes},
  year = {2019},
  month = jan,
  volume = {19},
  pages = {3595},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/s19163595},
  abstract = {Detection and classification of tree species from remote sensing data were performed using mainly multispectral and hyperspectral images and Light Detection And Ranging (LiDAR) data. Despite the comparatively lower cost and higher spatial resolution, few studies focused on images captured by Red-Green-Blue (RGB) sensors. Besides, the recent years have witnessed an impressive progress of deep learning methods for object detection. Motivated by this scenario, we proposed and evaluated the usage of Convolutional Neural Network (CNN)-based methods combined with Unmanned Aerial Vehicle (UAV) high spatial resolution RGB imagery for the detection of law protected tree species. Three state-of-the-art object detection methods were evaluated: Faster Region-based Convolutional Neural Network (Faster R-CNN), YOLOv3 and RetinaNet. A dataset was built to assess the selected methods, comprising 392 RBG images captured from August 2018 to February 2019, over a forested urban area in midwest Brazil. The target object is an important tree species threatened by extinction known as Dipteryx alata Vogel (Fabaceae). The experimental analysis delivered average precision around 92\% with an associated processing times below 30 miliseconds.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/jbo/Zotero/storage/5HT5DXPD/Santos et al. - 2019 - Assessment of CNN-Based Methods for Individual Tre.pdf;/home/jbo/Zotero/storage/E4WT57NV/3595.html},
  journal = {Sensors},
  keywords = {deep learning,object-detection,remote sensing},
  language = {en},
  number = {16}
}

@article{sharma2019performance,
  title = {Performance Analysis of Deep Learning {{CNN}} Models for Disease Detection in Plants Using Image Segmentation},
  author = {Sharma, Parul and Berwal, Yash Paul Singh and Ghai, Wiqas},
  year = {2019},
  month = nov,
  issn = {2214-3173},
  doi = {10.1016/j.inpa.2019.11.001},
  abstract = {Food security for the 7 billion people on earth requires minimizing crop damage by timely detection of diseases. Most deep learning models for automated detection of diseases in plants suffer from the fatal flaw that once tested on independent data, their performance drops significantly. This work investigates a potential solution to this problem by using segmented image data to train the convolutional neural network (CNN) models. As compared to the F-CNN model trained using full images, S-CNN model trained using segmented images more than doubles in performance to 98.6\% accuracy when tested on independent data previously unseen by the models even with 10 disease classes. Not only this, by using tomato plant and target spot disease type as an example, we show that the confidence of self-classification for S-CNN model improves significantly over F-CNN model. This research work brings applicability of automated methods closer to non-experts for timely detection of diseases.},
  file = {/home/jbo/Zotero/storage/DYQ3WXCA/S2214317319301957.html},
  journal = {Information Processing in Agriculture},
  keywords = {Image segmentation,Machine learning,Plant disease detection},
  language = {en}
}

@article{shorten2019survey,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = {2019},
  month = jul,
  volume = {6},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
  file = {/home/jbo/Zotero/storage/KRBMYU8Q/Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf;/home/jbo/Zotero/storage/3GUVUYPB/s40537-019-0197-0.html},
  journal = {Journal of Big Data},
  keywords = {Big data,Data Augmentation,Deep Learning,GANs,Image data},
  number = {1}
}

@article{simonyan2015very,
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  year = {2015},
  month = apr,
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  archiveprefix = {arXiv},
  eprint = {1409.1556},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/EDIHMBAU/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;/home/jbo/Zotero/storage/B6FUNL9Q/1409.html},
  journal = {arXiv:1409.1556 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{simpson1996treecaused,
  title = {{{TREE}}-{{CAUSED ELECTRIC OUTAGES}}},
  author = {Simpson, P. and Van Bossuyt, R.},
  year = {1996},
  volume = {22},
  pages = {117--121},
  abstract = {In 1995, Eastern Utilities was among 14 utilities in the United States and Canada participating in a study to collect and evaluate data about the phenomena of how trees cause outages. Results indicate that failure of trees accounted for 40\% of the preventable tree-caused outages in the Brockton territory of Eastern Utilities. Even though line clearance tree trimming continues to be the primary strategy, programmatic changes were made in Eastern Utilities\&\#39; Tree Management Program. A Danger Tree Project was initiated to identify and mitigate trees with structural weaknesses along the 3-phase portion of the electrical distribution circuits. Approximately 4\% of the trees in the portion of the urban forest managed by Eastern Utilities will either be removed or stormproof pruned. Reliability has improved by 20\% to 30\% along the circuits where hazardous trees have been removed or storm-proof pruning has been done. Proactive communication within the community and participation in communitybased tree planting has accompanied this project. Electric utilities trim trees to minimize treecaused electrical outages. (Outages are the interruption of electrical service to customers.) Typically, the expense to trim trees is a significant percentage of the maintenance budget of an electric utility. In spite of this expenditure, trees continue to be the greatest single cause of outages for many electric utilities. To minimize tree-caused outages, maintaining clearance between tree growth and energized conductors is the strategy for most utility tree management programs. Yet the phenomenon of tree-caused outages has not been empirically researched. In 1995, 14 utilities in the United States and Canada subscribed to the Tree-Caused Interruption Research Project conducted by Environmental Consultants, Inc. (ECI). The outage study consisted of a survey to collect and analyze data about individual tree-related outage events. The goal of the study was to develop regional and overall databases to identify and analyze the factors involved with tree-related outages. Eastern Utilities was a participant in the study. Results of the study led to programmatic adjustments in Eastern Utilities\&\#39; approach to tree management, consisting of a modification of practices for line clearance tree trimming and initiating a Danger Tree Mitigation Project. These changes were based on the study\&\#39;s cumulative analysis for all participants, a study analysis specific to Eastern Utilities, a survey of the tree population adjacent to primary electrical circuits in one of Eastern Utilities\&\#39; service territories, and a review of the outage history from trees at Eastern Utilities for the years 1989 to 1994. Methods The study was designed to collect data on 22 factors that describe the conditions of a treerelated electrical outage. A standardized data collection form was designed by ECI with input from the participants of the study. Data compilation and analysis was done by the ECI staff. Eastern Utilities also conducted a survey of the urban forest adjacent to the primary electrical circuits of the distribution network in its Brockton service territory and reviewed the outage history from 1989 to 1994. The primary electrical circuits consist of pole spans with single and multiple electrical conductors, called phases. The survey was designed to locate trees on the 3-phase portions of these circuits with the characteristics that are most likely to cause an outage. Also, an outage history of the primary circuits was reviewed to identify areas that have been historically prone to treecaused outages. Data collected for outage study. The study was organized to collect data on tree-caused outages by the following 6 categories: 1. cause of the outage 2. characteristics of the tree 3. surrounding environment 4. orientation of tree to electrical conductor 118 Simpson and Van Bossuyt: Tree-Caused Outages 5. weather conditions at the time that the outage occurred 6. components and design of the electrical system at the site of the outage. In addition, the arborist assessed whether the outage was preventable or nonpreventable. This assessment was based on whether the tree would still have caused the outage after the normal cycle of line clearance trimming was done. For instance, if a tree with adequate clearance and no apparent indicators of structural weakness fails during a sunny winter day with 25 mile per hour winds, it was considered nonpreventable. The categories describing the cause of the outage were broken down into growth or failure. The 3 growth-related indicators are top growth, side growth, or bending limb. Tree failures were matched with a choice of 6 descriptors. The type of contact made between the energized conductor and tree, such as tree to conductor or tree broke conductor, was recorded. Characteristics of the tree classify typical physical features of the tree such as size and species. The condition of the tree that failed has 14 subcategories that describe the apparent structural defect (or lack of) that probably resulted in an outage. Also, the last time the tree was trimmed, if ever, and the technique used was logged. Information about the surrounding environment, orientation of the tree to the electrical conductor, and weather conditions at the time the outage occurred was collected. These factors describe the conditions that likely triggered a treecaused outage event. The data about wind conditions were categorized using the Beaufort Scale and orientation of the tree to the electrical conductor. The weather was classified by 10 general descriptions. The type of construction and type of conductor at the site of an outage were recorded. Six data were collected that depict the electrical engineering portion of the outage event. The factors are 1. protective device, such as fuses 2. construction type, such as armless, vertical, spacer cable, and crossarm 3. conductor type 4. conductor size 5. line voltage 6. number of phases involved. Tree population survey. A survey of the tree population was conducted in the Brockton territory of the Eastern Utilities system. The territory consists of 17 communities and covers approximately 300 square miles. The objective of the survey was to locate trees with the characteristics that present the greatest risk from failure to the 3phase portion of the distribution circuits. The survey was a simple random sample of 40\% of the number of pole spans for the 3-phase portion of the primary electrical circuits. Random pole spans were selected on a map of primary circuits and the characteristics of the trees within those pole spans were categorized. The trees were categorized along the following 6 indicators of their potential to cause an outage from failure: 1. no predictor of potential failure 2. visible structural defect 3. overhanging limbs 4. weak species 5. white pines with co-dominant stems 6. no potential low growing species.},
  file = {/home/jbo/Zotero/storage/5NV6BVHR/7dc9d5b69971a12e4130f4deac938390dffae914.html},
  journal = {Journal of Arboriculture},
  language = {en}
}

@techreport{smiley2017best,
  title = {Best {{Management Practices}} - {{Tree Risk Assessment}}, {{Second Edition}}},
  author = {Smiley, E. Thomas and Matheny, Nelda and Lilly, Sharon},
  year = {2017},
  pages = {86},
  institution = {{International Society of Arboriculture}},
  file = {/home/jbo/Zotero/storage/T364UTGB/324.html},
  number = {P1542}
}

@article{snider1967proposed,
  title = {A {{Proposed Model}} for {{Visual Information Processing}} in the {{Human Brain}}},
  author = {Snider, Ray S.},
  year = {1967},
  month = jun,
  volume = {17},
  pages = {625--625},
  publisher = {{Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}},
  issn = {0028-3878, 1526-632X},
  doi = {10.1212/WNL.17.6.625},
  chapter = {BOOK REVIEWS},
  copyright = {\textcopyright{} 1967 by the American Academy of Neurology},
  file = {/home/jbo/Zotero/storage/B9Y46JVN/625.html},
  journal = {Neurology},
  language = {en},
  number = {6}
}

@article{spencer2019advances,
  title = {Advances in {{Computer Vision}}-{{Based Civil Infrastructure Inspection}} and {{Monitoring}}},
  author = {Spencer, Billie F. and Hoskere, Vedhus and Narazaki, Yasutaka},
  year = {2019},
  month = apr,
  volume = {5},
  pages = {199--222},
  issn = {2095-8099},
  doi = {10.1016/j.eng.2018.11.030},
  abstract = {Computer vision techniques, in conjunction with acquisition through remote cameras and unmanned aerial vehicles (UAVs), offer promising non-contact solutions to civil infrastructure condition assessment. The ultimate goal of such a system is to automatically and robustly convert the image or video data into actionable information. This paper provides an overview of recent advances in computer vision techniques as they apply to the problem of civil infrastructure condition assessment. In particular, relevant research in the fields of computer vision, machine learning, and structural engineering is presented. The work reviewed is classified into two types: inspection applications and monitoring applications. The inspection applications reviewed include identifying context such as structural components, characterizing local and global visible damage, and detecting changes from a reference image. The monitoring applications discussed include static measurement of strain and displacement, as well as dynamic measurement of displacement for modal analysis. Subsequently, some of the key challenges that persist toward the goal of automated vision-based civil infrastructure and monitoring are presented. The paper concludes with ongoing work aimed at addressing some of these stated challenges.},
  file = {/home/jbo/Zotero/storage/XBWA6DJA/Spencer et al. - 2019 - Advances in Computer Vision-Based Civil Infrastruc.pdf;/home/jbo/Zotero/storage/VALXK664/S2095809918308130.html},
  journal = {Engineering},
  keywords = {Artificial intelligence,Computer vision,Machine learning,Optical flow,Structural inspection and monitoring},
  language = {en},
  number = {2}
}

@article{su2020deep,
  title = {Deep Convolutional Neural Network\textendash Based Pixel-Wise Landslide Inventory Mapping},
  author = {Su, Zhaoyu and Chow, Jun Kang and Tan, Pin Siang and Wu, Jimmy and Ho, Ying Kit and Wang, Yu-Hsing},
  year = {2020},
  month = oct,
  issn = {1612-5118},
  doi = {10.1007/s10346-020-01557-6},
  abstract = {This paper reports a feasible alternative to compile a landslide inventory map (LIM) from remote sensing datasets using the application of an artificial intelligence\textendash driven methodology. A deep convolutional neural network model, called LanDCNN, was developed to generate segmentation maps of landslides, and its performance was compared with the benchmark model, named U-Net, and other conventional object-based methods. The landslides that occurred in Lantau Island, Hong Kong, were taken as the case study, in which the pre- and post-landslide aerial images, and a rasterized digital terrain model (DTM) were used. The assessment reveals that LanDCNN trained with bitemporal images and DTM yields the smoothest and most semantically meaningfully LIM, compared to other methods. This LIM is the most balanced segmentation results, represented by the highest F1 measure among all analyzed cases. With the encoding capability of LanDCNN, the application of DTM as the input renders better LIM production, especially when the landslide signatures are relatively subtle. With the computational setup used in this study, LanDCNN requires \textasciitilde\,3~min to map landslides from the datasets of approximately 25~km2 in area and with a resolution of 0.5~m. In short, the proposed landslide mapping framework, featured LanDCNN, is scalable to handle the vast amount of remote sensing data from different types of measurements within a short processing period.},
  journal = {Landslides},
  language = {en}
}

@article{szegedy2014going,
  title = {Going {{Deeper}} with {{Convolutions}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  year = {2014},
  month = sep,
  abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  archiveprefix = {arXiv},
  eprint = {1409.4842},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/KQA74U2N/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf;/home/jbo/Zotero/storage/YBTAGNDL/1409.html},
  journal = {arXiv:1409.4842 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{szegedy2015rethinking,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  year = {2015},
  month = dec,
  abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
  archiveprefix = {arXiv},
  eprint = {1512.00567},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/DX4MUTIZ/Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer.pdf;/home/jbo/Zotero/storage/QB32ED7K/1512.html},
  journal = {arXiv:1512.00567 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{szegedy2016inceptionv4,
  title = {Inception-v4, {{Inception}}-{{ResNet}} and the {{Impact}} of {{Residual Connections}} on {{Learning}}},
  author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
  year = {2016},
  month = aug,
  abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge},
  archiveprefix = {arXiv},
  eprint = {1602.07261},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/YGLIIRDT/Szegedy et al. - 2016 - Inception-v4, Inception-ResNet and the Impact of R.pdf;/home/jbo/Zotero/storage/JI8DJ6WI/1602.html},
  journal = {arXiv:1602.07261 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@inproceedings{touvron2019fixing,
  title = {Fixing the Train-Test Resolution Discrepancy},
  booktitle = {33rd {{Conference}} on {{Neural Information Processing System}}},
  author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
  year = {2019},
  pages = {11},
  address = {{Vancouver, Canada}},
  abstract = {Data-augmentation is key to the training of neural networks for image classification. This paper first shows that existing augmentations induce a significant discrepancy between the size of the objects seen by the classifier at train and test time: in fact, a lower train resolution improves the classification at test time! We then propose a simple strategy to optimize the classifier performance, that employs different train and test resolutions. It relies on a computationally cheap fine-tuning of the network at the test resolution. This enables training strong classifiers using small training images, and therefore significantly reduce the training time. For instance, we obtain 77.1\% top-1 accuracy on ImageNet with a ResNet50 trained on 128{$\RightArrowBar$}128 images, and 79.8\% with one trained at 224{$\RightArrowBar$}224.},
  file = {/home/jbo/Zotero/storage/HYCFSQPU/Touvron et al. - Fixing the train-test resolution discrepancy.pdf},
  language = {en}
}

@article{wang2019novel,
  title = {Novel {{System}} for {{Rapid Investigation}} and {{Damage Detection}} in {{Cultural Heritage Conservation Based}} on {{Deep Learning}}},
  author = {Wang, Niannian and Zhao, Xuefeng and Wang, Linan and Zou, Zheng},
  year = {2019},
  month = sep,
  volume = {25},
  pages = {04019020},
  publisher = {{American Society of Civil Engineers}},
  issn = {1943-555X},
  doi = {10.1061/(ASCE)IS.1943-555X.0000499},
  abstract = {Rapid investigation and damage assessment are crucial for cultural heritage conservation. At present, mobile crowd sensing (MCS) techniques are very effective for cultural heritage investigation and data collection. Unfortunately, data collected based on MCS techniques cannot be fully utilized and analyzed. To overcome this limitation, this study combines MCS techniques and a state-of-the-art deep learning algorithm to realize rapid investigation and damage detection of the Great Wall in China. The GreatWatcher system, based on MCS techniques and a deep learning algorithm, was developed in this study, focusing on big data collection and damage detection for the Great Wall. The system highlights the significance and emerging revolution of the combination MCS techniques with deep learning methods in the cultural heritage field. System components include a mobile client (data collection), web platform (data storage database), and computing terminal (data analysis and automatic damage detection). Two field investigations and data collection for the Great Wall were performed to verify the feasibility and effectiveness of the system. Based on the collected data, a deep learning method was used to automatically analyze damage to the Great Wall at the computing terminal. Moreover, various validation experiments of different conditions were performed to verify the good performance of the deep learning method.},
  copyright = {\textcopyright 2019 American Society of Civil Engineers},
  file = {/home/jbo/Zotero/storage/ASRUP38U/Wang et al. - 2019 - Novel System for Rapid Investigation and Damage De.pdf;/home/jbo/Zotero/storage/HQLSI224/(ASCE)IS.1943-555X.html},
  journal = {Journal of Infrastructure Systems},
  keywords = {Damage detection,Deep learning,Faster R-convolution neural network (CNN),GreatWatcher system,Mobile crowd sensing (MCS)},
  language = {EN},
  number = {3}
}

@misc{wismer2018targeted,
  title = {Targeted {{Tree Trimming Offers Reliability Benefits}}},
  author = {Wismer, Shaun},
  year = {2018},
  month = may,
  abstract = {ComEd uses tree-related outage data to augment its vegetation management program and bolster its storm-hardening efforts.},
  file = {/home/jbo/Zotero/storage/E8ZMF4VP/targeted-tree-trimming-offers-reliability-benefits.html},
  howpublished = {https://www.tdworld.com/vegetation-management/article/20971285/targeted-tree-trimming-offers-reliability-benefits},
  journal = {T\&D World},
  language = {en-us}
}

@article{wong2016understanding,
  title = {Understanding Data Augmentation for Classification: When to Warp?},
  shorttitle = {Understanding Data Augmentation for Classification},
  author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D.},
  year = {2016},
  month = nov,
  abstract = {In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.},
  archiveprefix = {arXiv},
  eprint = {1609.08764},
  eprinttype = {arxiv},
  file = {/home/jbo/Zotero/storage/IW25QA6S/Wong et al. - 2016 - Understanding data augmentation for classification.pdf;/home/jbo/Zotero/storage/N8BFKIXV/1609.html},
  journal = {arXiv:1609.08764 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.7,I.5.2},
  primaryclass = {cs}
}

@inproceedings{wyatt1988method,
  title = {A {{Method}} for the {{Design}} of {{Stable Lateral Inhibition Networks}} That Is {{Robust}} in the {{Presence}} of {{Circuit Parasitics}}},
  booktitle = {Neural {{Information Processing Systems}}},
  author = {Wyatt, John and Standley, D.},
  editor = {Anderson, D.},
  year = {1988},
  pages = {860--868},
  publisher = {{American Institute of Physics}},
  file = {/home/jbo/Zotero/storage/TWSGPL3Y/53c3bce66e43be4f209556518c2fcb54-Abstract.html}
}

@article{xie2020promise,
  title = {The Promise of Implementing Machine Learning in Earthquake Engineering: {{A}} State-of-the-Art Review},
  shorttitle = {The Promise of Implementing Machine Learning in Earthquake Engineering},
  author = {Xie, Yazhou and Ebad Sichani, Majid and Padgett, Jamie E and DesRoches, Reginald},
  year = {2020},
  month = nov,
  volume = {36},
  pages = {1769--1801},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {8755-2930},
  doi = {10.1177/8755293020919419},
  abstract = {Machine learning (ML) has evolved rapidly over recent years with the promise to substantially alter and enhance the role of data science in a variety of disciplines. Compared with traditional approaches, ML offers advantages to handle complex problems, provide computational efficiency, propagate and treat uncertainties, and facilitate decision making. Also, the maturing of ML has led to significant advances in not only the main-stream artificial intelligence (AI) research but also other science and engineering fields, such as material science, bioengineering, construction management, and transportation engineering. This study conducts a comprehensive review of the progress and challenges of implementing ML in the earthquake engineering domain. A hierarchical attribute matrix is adopted to categorize the existing literature based on four traits identified in the field, such as ML method, topic area, data resource, and scale of analysis. The state-of-the-art review indicates to what extent ML has been applied in four topic areas of earthquake engineering, including seismic hazard analysis, system identification and damage detection, seismic fragility assessment, and structural control for earthquake mitigation. Moreover, research challenges and the associated future research needs are discussed, which include embracing the next generation of data sharing and sensor technologies, implementing more advanced ML techniques, and developing physics-guided ML models.},
  journal = {Earthquake Spectra},
  keywords = {earthquake engineering,Machine learning,seismic fragility assessment,seismic hazard analysis,structural control,system identification and damage detection},
  language = {en},
  number = {4}
}

@article{xu2020advances,
  title = {Advances in {{Convolutional Neural Networks}}},
  author = {Xu, Wen and He, Jing and Shu, Yanfeng and Zheng, Hui},
  year = {2020},
  month = oct,
  publisher = {{IntechOpen}},
  doi = {10.5772/intechopen.93512},
  abstract = {Deep Learning, also known as deep representation learning, has dramatically improved the performances on a variety of learning tasks and achieved tremendous successes in the past few years. Specifically, artificial neural networks are mainly studied, which mainly include Multilayer Perceptrons (MLPs), Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). Among these networks, CNNs got the most attention due to the kernel methods with the weight sharing mechanism, and achieved state-of-the-art in many domains, especially computer vision. In this research, we conduct a comprehensive survey related to the recent improvements in CNNs, and we demonstrate these advances from the low level to the high level, including the convolution operations, convolutional layers, architecture design, loss functions, and advanced applications.},
  file = {/home/jbo/Zotero/storage/J48588MB/Xu et al. - 2020 - Advances in Convolutional Neural Networks.pdf;/home/jbo/Zotero/storage/6V98RISX/advances-in-convolutional-neural-networks.html},
  journal = {Advances and Applications in Deep Learning},
  language = {en}
}

@inproceedings{zeiler2014visualizing,
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2014},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  year = {2014},
  pages = {818--833},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-10590-1_53},
  abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  file = {/home/jbo/Zotero/storage/Q88LSQRG/Zeiler and Fergus - 2014 - Visualizing and Understanding Convolutional Networ.pdf},
  isbn = {978-3-319-10590-1},
  keywords = {Convolutional Neural Network,Input Image,Pixel Space,Stochastic Gradient Descent,Training Image},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}


